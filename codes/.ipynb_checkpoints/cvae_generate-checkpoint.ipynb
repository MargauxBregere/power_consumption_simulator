{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script allows the generation of nb_init decoders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# charge library and fix the seed\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import glob\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "tf.config.experimental_run_functions_eagerly(True)\n",
    "from cvae import CVAE\n",
    "import random\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the daily exogeous variables used to train CVAEs:  \n",
    "#       rescaled temperatures (3 temperatures computed using a dimensionallity reduction method - PCA)\n",
    "#       a smooth rescaled temperature \n",
    "#       position in the year (0 on January 1., 1 on December, 31.)\n",
    "#       working day or not \n",
    "#       tariff daily profile (48 * 2 = 96 variables : 48 with 1 if tariff is Low, 0 if not and 48 with 1 if tariff is High, 0 if not)\n",
    "cols_data = []\n",
    "cols_price = []\n",
    "cols_temp = ['temp_smooth_n']\n",
    "for i in range(48):\n",
    "    cols_data.append('consumption_{:02}'.format(i))\n",
    "    cols_price.append('low_{:02}'.format(i))\n",
    "    cols_price.append('high_{:02}'.format(i))\n",
    "\n",
    "for i in range(3):\n",
    "    cols_temp.append('pca_temp_{:1}'.format(i))\n",
    "cols_cond = cols_temp + ['pos_y', 'work_day'] + cols_price \n",
    "cond_dim = len(cols_cond) \n",
    "\n",
    "# set hyper parameters and epoch number\n",
    "epochs = 50\n",
    "input_dim = 48\n",
    "nb_layers_encoder=2\n",
    "nb_layers_decoder=2\n",
    "units_layers_encoder=[15,8]\n",
    "units_layers_decoder=[15,48]\n",
    "weights_decoder = None\n",
    "weights_encoder = None\n",
    "initializer = tf.keras.initializers.glorot_uniform(seed=0)\n",
    "latent_dim = 4\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
    "activation = 'relu'\n",
    "moving_kl_coeff = 'constant'\n",
    "kl_coeff = 10\n",
    "nb_init = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cvae(clustering_name):\n",
    "    # charge train set\n",
    "    df_train = pd.read_feather('../data/train_' + clustering_name + '.feather')\n",
    "    df_train['date'] = pd.to_datetime(df_train['date'])\n",
    "\n",
    "    if (clustering_name!='Std') & (clustering_name!='ToU'):\n",
    "        nb_cluster = 4\n",
    "        clusters = pd.read_feather('../data/sum_up_' + clustering_name + '.feather')\n",
    "        nb_clust = clusters.cluster.size\n",
    "        clusters = clusters.set_index('cluster')\n",
    "        cols_clust = []\n",
    "        for c in clusters.index:\n",
    "            df_train['cluster_{:02}'.format(c)] = np.array(1 * (df_train['cluster'] == c), dtype='float64')\n",
    "            cols_clust.append('cluster_{:02}'.format(c))\n",
    "    else: \n",
    "        nb_cluster=1\n",
    "    # loop on cluster: a CVAE per cluser \n",
    "    for c in range(nb_cluster):\n",
    "        print(c)\n",
    "        \n",
    "        # select corresponding data train set\n",
    "        if (clustering_name!='Std') & (clustering_name!='ToU'):\n",
    "            df_train_c = df_train.loc[df_train['cluster_{:02}'.format(c)] == 1]\n",
    "        else:\n",
    "            df_train_c = df_train\n",
    "                \n",
    "        # rescale data between 0 and 1\n",
    "        conso_max = max(df_train_c.loc[:,cols_data].max())\n",
    "        conso_min = min(df_train_c.loc[:,cols_data].min())\n",
    "        df_train_c.loc[:,cols_data] = (df_train_c.loc[:,cols_data]-conso_min)/(conso_max-conso_min)\n",
    "\n",
    "        # convert data train set into a tensor\n",
    "        d0 = df_train_c.index[0]\n",
    "        df_train_tf = tf.reshape(df_train_c.loc[d0, cols_data], shape=[1, 48])\n",
    "        cond_train_tf = tf.reshape(df_train_c.loc[d0, cols_cond], shape=[1, cond_dim])\n",
    "        for d in df_train_c.index[1:len(df_train_c.index)]:\n",
    "            df_train_tf = tf.concat([df_train_tf, tf.reshape(df_train_c.loc[d, cols_data], shape=[1, 48])], 0)\n",
    "            cond_train_tf = tf.concat([cond_train_tf, tf.reshape(df_train_c.loc[d, cols_cond], shape=[1, cond_dim])], 0)\n",
    " \n",
    "        # loop on nb_init convergences of the cvae \n",
    "        for it in range(nb_init):\n",
    "\n",
    "            # define model\n",
    "            model = CVAE(input_dim, latent_dim, cond_dim, \n",
    "                 full_covariance_matrix= False, \n",
    "                 nb_layers_encoder=nb_layers_encoder,\n",
    "                 units_layers_encoder=units_layers_encoder, \n",
    "                 nb_layers_decoder=nb_layers_decoder,\n",
    "                 units_layers_decoder=units_layers_decoder,\n",
    "                 initializer_encoder=initializer,\n",
    "                 weights_encoder = weights_encoder,\n",
    "                 initializer_decoder=initializer,\n",
    "                 weights_decoder = weights_decoder,             \n",
    "                 activation=activation, \n",
    "                 optimizer=optimizer,\n",
    "                 loss='L2')\n",
    "        \n",
    "            # optimize model\n",
    "            for epoch in range(epochs):\n",
    "                if moving_kl_coeff == 'linear':\n",
    "                    eta = (epoch/epochs)*kl_coeff\n",
    "                if moving_kl_coeff == 'sigmoid':\n",
    "                    x = -6 + 12*epoch/epochs \n",
    "                    eta = (1/(1+np.math.exp(-x)))*kl_coeff\n",
    "                if moving_kl_coeff == 'constant':   \n",
    "                    eta = 1 * kl_coeff\n",
    "                model.train_step(df_train_tf, cond_train_tf, eta)\n",
    "            # save model    \n",
    "            if (clustering_name!='Std') & (clustering_name!='ToU'):\n",
    "                model.decoder_net.save('../decoders/test/' + clustering_name +'cluster_' + str(c) + '_' + str(it) + '.h5')\n",
    "            else:\n",
    "                model.decoder_net.save('../decoders/test/' + clustering_name + '_' + str(it) + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_cvae('nmf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
